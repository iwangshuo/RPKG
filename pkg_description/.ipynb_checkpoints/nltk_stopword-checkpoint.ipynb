{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48315e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "FILE_PATH = '../data/index.csv'\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# remove \"up\" and \"down\"\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n",
    "for w in ['!',',','.','?','','s','\\n','\\t']:\n",
    "    stopwords.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f80c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['features']=''\n",
    "for index,row in df.iterrows():\n",
    "#     print(index)\n",
    "    total_num = 400\n",
    "    if (index < total_num) and (type(df.iloc[index,1]) == type('1')):\n",
    "        # deal with the text\n",
    "        sentence = []\n",
    "        for word in tokenizer.tokenize(df.iloc[index,1]):\n",
    "            if len(word) != 1 and (word.lower() not in stopwords):\n",
    "                sentence.append(word.lower())\n",
    "        df.iloc[index,3] = ','.join(sentence)\n",
    "    else:\n",
    "        df.iloc[index,0] = np.nan\n",
    "# delete the one with no distinct tendency in emotion\n",
    "df = df.dropna(axis=0,how='any')\n",
    "df.to_csv('./test_stop.csv', sep=',', index=False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79bc6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index,row in df.iterrows():\n",
    "#     print(df.iloc[index,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18380089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last_commit_date</th>\n",
       "      <th>package_description</th>\n",
       "      <th>package_name</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021/12/16</td>\n",
       "      <td>Launch files and scripts needed to bring up th...</td>\n",
       "      <td>reemc_bringup</td>\n",
       "      <td>launch,files,scripts,needed,bring,up,ros,nodes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021/12/10</td>\n",
       "      <td>This package retrieves data from url-format fi...</td>\n",
       "      <td>resource_retriever</td>\n",
       "      <td>package,retrieves,data,url,format,files,http,f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/12/8</td>\n",
       "      <td>Time-Indexed RRT-Connect solver (Humanoids 2018)</td>\n",
       "      <td>exotica_time_indexed_rrt_connect_solver</td>\n",
       "      <td>time,indexed,rrt,connect,solver,humanoids,2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021/12/8</td>\n",
       "      <td>SciPy-based Python solvers for Exotica</td>\n",
       "      <td>exotica_scipy_solver</td>\n",
       "      <td>scipy,based,python,solvers,exotica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021/12/8</td>\n",
       "      <td>Quadrotor dynamics solver plug-in for Exotica</td>\n",
       "      <td>exotica_quadrotor_dynamics_solver</td>\n",
       "      <td>quadrotor,dynamics,solver,plug,exotica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2021/5/7</td>\n",
       "      <td>Calibrates the offsets of F/T sensors and the ...</td>\n",
       "      <td>force_torque_sensor_calib</td>\n",
       "      <td>calibrates,offsets,sensors,mass,position,com,g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2021/5/4</td>\n",
       "      <td>Server Side tools for Authorization and Authen...</td>\n",
       "      <td>rosauth</td>\n",
       "      <td>server,side,tools,authorization,authentication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2021/5/3</td>\n",
       "      <td>The stag_ros package</td>\n",
       "      <td>stag_ros</td>\n",
       "      <td>stag_ros,package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2021/4/28</td>\n",
       "      <td>rqt_web is a simple web content viewer for rqt...</td>\n",
       "      <td>rqt_web</td>\n",
       "      <td>rqt_web,simple,web,content,viewer,rqt,users,sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2021/4/28</td>\n",
       "      <td>rqt_pose_view provides a GUI plugin for visual...</td>\n",
       "      <td>rqt_pose_view</td>\n",
       "      <td>rqt_pose_view,provides,gui,plugin,visualizing,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Last_commit_date                                package_description  \\\n",
       "0         2021/12/16  Launch files and scripts needed to bring up th...   \n",
       "1         2021/12/10  This package retrieves data from url-format fi...   \n",
       "2          2021/12/8   Time-Indexed RRT-Connect solver (Humanoids 2018)   \n",
       "3          2021/12/8             SciPy-based Python solvers for Exotica   \n",
       "4          2021/12/8      Quadrotor dynamics solver plug-in for Exotica   \n",
       "..               ...                                                ...   \n",
       "395         2021/5/7  Calibrates the offsets of F/T sensors and the ...   \n",
       "396         2021/5/4  Server Side tools for Authorization and Authen...   \n",
       "397         2021/5/3                               The stag_ros package   \n",
       "398        2021/4/28  rqt_web is a simple web content viewer for rqt...   \n",
       "399        2021/4/28  rqt_pose_view provides a GUI plugin for visual...   \n",
       "\n",
       "                                package_name  \\\n",
       "0                              reemc_bringup   \n",
       "1                         resource_retriever   \n",
       "2    exotica_time_indexed_rrt_connect_solver   \n",
       "3                       exotica_scipy_solver   \n",
       "4          exotica_quadrotor_dynamics_solver   \n",
       "..                                       ...   \n",
       "395                force_torque_sensor_calib   \n",
       "396                                  rosauth   \n",
       "397                                 stag_ros   \n",
       "398                                  rqt_web   \n",
       "399                            rqt_pose_view   \n",
       "\n",
       "                                              features  \n",
       "0    launch,files,scripts,needed,bring,up,ros,nodes...  \n",
       "1    package,retrieves,data,url,format,files,http,f...  \n",
       "2       time,indexed,rrt,connect,solver,humanoids,2018  \n",
       "3                   scipy,based,python,solvers,exotica  \n",
       "4               quadrotor,dynamics,solver,plug,exotica  \n",
       "..                                                 ...  \n",
       "395  calibrates,offsets,sensors,mass,position,com,g...  \n",
       "396  server,side,tools,authorization,authentication...  \n",
       "397                                   stag_ros,package  \n",
       "398  rqt_web,simple,web,content,viewer,rqt,users,sh...  \n",
       "399  rqt_pose_view,provides,gui,plugin,visualizing,...  \n",
       "\n",
       "[367 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "056b2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_features(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    features = [token.text for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "    compound_features = []\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.dep_ == 'compound' and i > 0:\n",
    "            if compound_features:\n",
    "                compound_features[-1] += f' {token.text}'\n",
    "            else:\n",
    "                compound_features.append(token.text)\n",
    "        elif token.pos_ != 'DET' and (token.dep_ == 'ROOT' or token.dep_ == 'amod' or token.dep_ == 'nsubj' or token.dep_ == 'dobj'):\n",
    "            compound_features.append(token.text)\n",
    "    return compound_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['features']=''\n",
    "for index,row in df.iterrows():\n",
    "#     print(index)\n",
    "    total_num = 400\n",
    "    if (index < total_num) and (type(df.iloc[index,1]) == type('1')):\n",
    "        features = extract_features(df.iloc[index,1])\n",
    "        df.iloc[index,3] = ','.join(features)\n",
    "\n",
    "    else:\n",
    "        df.iloc[index,0] = np.nan\n",
    "# delete the one with no distinct tendency in emotion\n",
    "df = df.dropna(axis=0,how='any')\n",
    "df.to_csv('./test_stop_chatgpt.csv', sep=',', index=False,header = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5c726b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamics compound\n",
      "solver compound\n",
      "plug ROOT\n",
      "- punct\n",
      "in prt\n",
      "using acl\n",
      "Pinocchio dobj\n",
      "for prep\n",
      "Exotica pobj\n"
     ]
    }
   ],
   "source": [
    "dd = nlp(\"Dynamics solver plug-in using Pinocchio for Exotica\")\n",
    "for i, token in enumerate(dd):\n",
    "    print(token, token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac736826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['solver', 'plug', 'Pinocchio']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(\"Dynamics solver plug-in using Pinocchio for Exotica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a30164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
